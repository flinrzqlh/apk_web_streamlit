{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEWpayxURuUn"
      },
      "source": [
        "# ***CRAWLING DATA TWITTER***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S00x_f6-GeD"
      },
      "outputs": [],
      "source": [
        "#@title Twitter Auth Token\n",
        "\n",
        "twitter_auth_token = 'put twt auth token here' # change this auth token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4UIL1x21P9rQ",
        "outputId": "f8acf114-9dd2-424c-8096-3528b1384e7b"
      },
      "outputs": [],
      "source": [
        "# Import required Python package\n",
        "!pip install pandas\n",
        "\n",
        "# Install Node.js (because tweet-harvest built using Node.js)\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y ca-certificates curl gnupg\n",
        "!sudo mkdir -p /etc/apt/keyrings\n",
        "!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg\n",
        "\n",
        "!NODE_MAJOR=20 && echo \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main\" | sudo tee /etc/apt/sources.list.d/nodesource.list\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install nodejs -y\n",
        "\n",
        "!node -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYDR51dJlVlX",
        "outputId": "5782b42f-f00c-48c1-f478-f860678c895b"
      },
      "outputs": [],
      "source": [
        "# Crawl Data\n",
        "\n",
        "filename = 'iisma.csv'\n",
        "search_keyword = 'iisma since:2023-04-01 until:2024-04-01 lang:id'\n",
        "limit = 300\n",
        "\n",
        "!npx -y tweet-harvest@2.6.1 -o \"{filename}\" -s \"{search_keyword}\" --tab \"LATEST\" -l {limit} --token {twitter_auth_token}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "HvAG3hPvQDqk",
        "outputId": "8558d3e3-e8fd-4df9-af7b-c96fa05b99f6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "file_path = f\"tweets-data/{filename}\"\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(file_path, delimiter=\",\")\n",
        "\n",
        "# Display the DataFrame\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRfDl54waHC4",
        "outputId": "e8082c84-dea5-41c1-f171-cc12a989c40e"
      },
      "outputs": [],
      "source": [
        "# Cek jumlah data yang didapatkan\n",
        "\n",
        "num_tweets = len(df)\n",
        "print(f\"Jumlah tweet dalam dataframe adalah {num_tweets}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi_LYe9_hb_9"
      },
      "source": [
        "# ***PRE-PROCESSING DATA***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "luQh95t4hnBJ",
        "outputId": "5aa128b7-1b85-49d2-a452-23aa1fe179c8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Specify the path to your CSV file\n",
        "file_path = f\"tweets-data/{filename}\"\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "data = pd.read_csv(file_path, delimiter=\",\")\n",
        "\n",
        "# Display the DataFrame\n",
        "display(data)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T1s2Rqni2tI",
        "outputId": "b05ac3ad-54bd-4f0f-87fb-215fbbd8a544"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuhwd4zmi-4Z",
        "outputId": "864d8337-04a0-428a-9a1e-94b2ab646f8b"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates(subset='full_text', keep = 'first', inplace=True)\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "44Yr6JUMjcEf",
        "outputId": "b64e7bd1-b815-416a-fd1d-ba01e315e741"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data['full_text'])\n",
        "df.head(319)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r74S-pxj7bj"
      },
      "source": [
        "Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oJnVZL3Uj4cZ",
        "outputId": "fa910756-66f1-4830-9e71-fbc14407024f"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "def remove_URL(tweet):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'', tweet)\n",
        "\n",
        "def remove_html(tweet):\n",
        "    html = re.compile(r'<.*?>')\n",
        "    return html.sub(r'', tweet)\n",
        "\n",
        "def remove_emoji(tweet):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "      u\"\\U0001F600-\\U0001F64F\"\n",
        "      u\"\\U0001F300-\\U0001F5FF\"\n",
        "      u\"\\U0001F680-\\U0001F6FF\"\n",
        "      u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "      \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', tweet)\n",
        "\n",
        "def remove_angka(tweet):\n",
        "    tweet = re.sub(r'\\d+', '', tweet)\n",
        "    return tweet\n",
        "\n",
        "def remove_symbols(tweet):\n",
        "    tweet = re.sub(r'[^a-zA-Z0-9\\s]', '', tweet)\n",
        "    return tweet\n",
        "\n",
        "df['cleaning'] = df['full_text'].apply(lambda x: remove_URL(x))\n",
        "df['cleaning'] = df['cleaning'].apply(lambda x: remove_html(x))\n",
        "df['cleaning'] = df['cleaning'].apply(lambda x: remove_emoji(x))\n",
        "df['cleaning'] = df['cleaning'].apply(lambda x: remove_symbols(x))\n",
        "df['cleaning'] = df['cleaning'].apply(lambda x: remove_angka(x))\n",
        "\n",
        "df.head(319)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_js_7IMlUKq"
      },
      "source": [
        "CASE FOLDING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "PMFoHQiflTzC",
        "outputId": "911ed7af-f28a-47ba-f457-aad1723c4911"
      },
      "outputs": [],
      "source": [
        "def case_folding(text):\n",
        "    if isinstance(text, str):\n",
        "        lowercase_text = text.lower()\n",
        "        return lowercase_text\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "df['case_folding'] = df['cleaning'].apply(case_folding)\n",
        "df.head(319)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9orui6jCmYAH"
      },
      "source": [
        "TOKENIZATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "0dYs-96HmXuT",
        "outputId": "11cba49d-2c94-4bf1-a177-48460d7f8560"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "df['tokenize'] = df['case_folding'].apply(tokenize)\n",
        "df.head(319)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uopkD2anmw7M"
      },
      "source": [
        "FILTERING/STOPWORD REMOVAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnBVG_2km0Xc",
        "outputId": "65cdc06c-d032-4deb-8bf8-43fd0d007fbb"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('indonesian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "9ipYid8Wm6IY",
        "outputId": "85c4256b-54a6-4eb2-bb78-cd5eb8710728"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    return [word for word in text if word not in stop]\n",
        "\n",
        "df['filtering/stopword removal'] = df['tokenize'].apply(lambda x: remove_stopwords(x))\n",
        "df.head(319)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeWxjIu7nCVC"
      },
      "source": [
        "STEAMING DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Za_5LGtnDvR",
        "outputId": "71dc9c29-5fe6-4baa-8827-13ba673c5df0"
      },
      "outputs": [],
      "source": [
        "!pip install Sastrawi\n",
        "\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "RV1vsrg_nNg9",
        "outputId": "51819a3a-71e9-42aa-8f79-ef47097c6e73"
      },
      "outputs": [],
      "source": [
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def stem_text(text):\n",
        "    return [stemmer.stem(word) for word in text]\n",
        "\n",
        "df['steaming_data'] = df['filtering/stopword removal'].apply(lambda x: ' '.join(stem_text(x)))\n",
        "df.head(319)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FFvs--aoSxt"
      },
      "source": [
        "EXPORT PRE-PROCESSED DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "Ks_75Mm-oVbn"
      },
      "outputs": [],
      "source": [
        "df.to_csv('preproc.csv', encoding='utf8', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-NC4WOa5D43"
      },
      "source": [
        "# ***LABELLING DATA***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "Hg0xMnem5Ixo",
        "outputId": "725a21dc-6a8d-48f3-a434-0dbf0fda3745"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_data():\n",
        "    data = pd.read_csv('preproc.csv')\n",
        "    return data\n",
        "\n",
        "data = load_data()\n",
        "data.head(319)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pXxY-316Ypw",
        "outputId": "6e772787-8782-4c36-b8db-00266b0893de"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mJKxcF5c76VQ",
        "outputId": "717f99e6-39df-48bf-b274-cca7d79c2154"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data['steaming_data'])\n",
        "df.head(319)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzShy7AB8KrA",
        "outputId": "47435f7f-136d-42d5-f159-ef2ee4dd39da"
      },
      "outputs": [],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "IFjakWxEMbO6",
        "outputId": "75fd528c-9a1c-489b-b016-c5fe0ff90362"
      },
      "outputs": [],
      "source": [
        "data = SentimentIntensityAnalyzer()\n",
        "labels = []\n",
        "scores = []\n",
        "\n",
        "for text in df['steaming_data']:\n",
        "    sentiment_scores = data.polarity_scores(text)\n",
        "    compound_score = sentiment_scores['compound']\n",
        "\n",
        "    scores.append(compound_score)\n",
        "\n",
        "    if compound_score > 0:\n",
        "        labels.append('Positif')\n",
        "    elif compound_score < 0:\n",
        "        labels.append('Negatif')\n",
        "    else:\n",
        "        labels.append('Netral')\n",
        "\n",
        "df['sentiment'] = labels\n",
        "df['sentiment_score'] = scores\n",
        "\n",
        "data = ['steaming_data', 'sentiment_score', 'sentiment']\n",
        "data = df[data]\n",
        "\n",
        "data.head(319)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "yWZzPOikfshG",
        "outputId": "15c89246-cc1f-4112-f80b-1b9949c0124d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sentiment_count = data['sentiment'].value_counts()\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax = sns.barplot(x=sentiment_count.index, y=sentiment_count.values, palette='pastel')\n",
        "plt.title('Jumlah Analisis Sentimen', fontsize=14, pad=20)\n",
        "plt.xlabel('Class Sentiment', fontsize=12)\n",
        "plt.ylabel('Jumlah Tweet', fontsize=12)\n",
        "\n",
        "for i, count in enumerate(sentiment_count.values):\n",
        "    ax.text(i, count + 0.10, str(count), ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "c9IUEujEhP75"
      },
      "outputs": [],
      "source": [
        "data.to_csv('labelNLTK.csv', encoding='utf8', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Hi_LYe9_hb_9",
        "m-NC4WOa5D43"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
